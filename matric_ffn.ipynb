{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "#os.chdir(os.curdir + '/work/project/code')\n",
    "from part import Part\n",
    "from evaluation import MyPredictionModel, evaluate\n",
    "from graph import Graph\n",
    "from typing import List, Set\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_node_features_and_adjacency_matrix(graph, max_nodes):\n",
    "    node_features = np.eye(max_nodes)[:len(graph.get_nodes())]\n",
    "    adj_matrix = nx.to_numpy_array(graph.to_nx())\n",
    "    padded_features = np.zeros((max_nodes, max_nodes))\n",
    "    padded_features[:node_features.shape[0], :node_features.shape[1]] = node_features\n",
    "    padded_matrix = np.zeros((max_nodes, max_nodes))\n",
    "    padded_matrix[:adj_matrix.shape[0], :adj_matrix.shape[1]] = adj_matrix\n",
    "    return padded_features, padded_matrix\n",
    "\n",
    "def prepare_data(graphs, max_nodes):\n",
    "    node_features_list = []\n",
    "    adj_matrices_list = []\n",
    "    for g in graphs:\n",
    "        node_features, adj_matrix = graph_to_node_features_and_adjacency_matrix(g, max_nodes)\n",
    "        node_features_list.append(node_features)\n",
    "        adj_matrices_list.append(adj_matrix)\n",
    "    return np.array(node_features_list), np.array(adj_matrices_list)\n",
    "\n",
    "# Load train data\n",
    "with open('data/graphs.dat', 'rb') as file:\n",
    "    train_graphs: List[Graph] = pickle.load(file)\n",
    "\n",
    "max_nodes = max(len(g.get_nodes()) for g in train_graphs)\n",
    "node_features, adj_matrices = prepare_data(train_graphs, max_nodes)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(node_features, adj_matrices, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441\n",
      "441\n"
     ]
    }
   ],
   "source": [
    "class FFNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(FFNModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        x = x.view(-1, max_nodes, max_nodes)\n",
    "        return x\n",
    "\n",
    "input_size = max_nodes * max_nodes\n",
    "output_size = max_nodes * max_nodes\n",
    "\n",
    "print(input_size)\n",
    "print(output_size)\n",
    "\n",
    "model = FFNModel(input_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.08466651312352616\n",
      "Epoch 2/50, Loss: 0.07022551001854054\n",
      "Epoch 3/50, Loss: 0.06925440865058091\n",
      "Epoch 4/50, Loss: 0.06874116810579453\n",
      "Epoch 5/50, Loss: 0.06844644632030239\n",
      "Epoch 6/50, Loss: 0.06816877983510494\n",
      "Epoch 7/50, Loss: 0.06803414382801581\n",
      "Epoch 8/50, Loss: 0.06790907364872728\n",
      "Epoch 9/50, Loss: 0.06785051119730784\n",
      "Epoch 10/50, Loss: 0.06776467194333405\n",
      "Epoch 11/50, Loss: 0.0677009848944549\n",
      "Epoch 12/50, Loss: 0.06764131189260539\n",
      "Epoch 13/50, Loss: 0.06762342727793161\n",
      "Epoch 14/50, Loss: 0.06758301408701045\n",
      "Epoch 15/50, Loss: 0.06754603388128422\n",
      "Epoch 16/50, Loss: 0.06755023910647331\n",
      "Epoch 17/50, Loss: 0.06750224817103596\n",
      "Epoch 18/50, Loss: 0.067477691985373\n",
      "Epoch 19/50, Loss: 0.06746233012994558\n",
      "Epoch 20/50, Loss: 0.06743386025310204\n",
      "Epoch 21/50, Loss: 0.06741073788360669\n",
      "Epoch 22/50, Loss: 0.06743039254526403\n",
      "Epoch 23/50, Loss: 0.06760146892145544\n",
      "Epoch 24/50, Loss: 0.06737163468634569\n",
      "Epoch 25/50, Loss: 0.0673932199062626\n",
      "Epoch 26/50, Loss: 0.0674002357227828\n",
      "Epoch 27/50, Loss: 0.06732535537158717\n",
      "Epoch 28/50, Loss: 0.06735401392303487\n",
      "Epoch 29/50, Loss: 0.06734956458117479\n",
      "Epoch 30/50, Loss: 0.06731391847000114\n",
      "Epoch 31/50, Loss: 0.06730040573718621\n",
      "Epoch 32/50, Loss: 0.06731281477597452\n",
      "Epoch 33/50, Loss: 0.06728876642816062\n",
      "Epoch 34/50, Loss: 0.06731586014070819\n",
      "Epoch 35/50, Loss: 0.06726651606366946\n",
      "Epoch 36/50, Loss: 0.06725566759772306\n",
      "Epoch 37/50, Loss: 0.06728251746732168\n",
      "Epoch 38/50, Loss: 0.06724832833187128\n",
      "Epoch 39/50, Loss: 0.0672310552155886\n",
      "Epoch 40/50, Loss: 0.06724438563950601\n",
      "Epoch 41/50, Loss: 0.06722742000321014\n",
      "Epoch 42/50, Loss: 0.06724234441408761\n",
      "Epoch 43/50, Loss: 0.06721846945250012\n",
      "Epoch 44/50, Loss: 0.06722941228912936\n",
      "Epoch 45/50, Loss: 0.06721031826697156\n",
      "Epoch 46/50, Loss: 0.06726177623261795\n",
      "Epoch 47/50, Loss: 0.06721475636619928\n",
      "Epoch 48/50, Loss: 0.06720764714703766\n",
      "Epoch 49/50, Loss: 0.06723121043267964\n",
      "Epoch 50/50, Loss: 0.06719859581988132\n",
      "Test Loss: 0.06804996148072263\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "print(f'Test Loss: {test_loss/len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score: 69.83%\n"
     ]
    }
   ],
   "source": [
    "class FFNPredictionModel(MyPredictionModel):\n",
    "    def __init__(self, model, max_nodes):\n",
    "        self.model = model\n",
    "        self.max_nodes = max_nodes\n",
    "\n",
    "    def predict_graph(self, parts: Set[Part]) -> Graph:\n",
    "        node_features = np.eye(self.max_nodes)[:len(parts)]\n",
    "        padded_features = np.zeros((self.max_nodes, self.max_nodes))\n",
    "        padded_features[:node_features.shape[0], :node_features.shape[1]] = node_features\n",
    "        padded_features_tensor = torch.tensor(padded_features, dtype=torch.float32).unsqueeze(0)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predicted_adj_matrix = self.model(padded_features_tensor).squeeze(0).numpy()\n",
    "        \n",
    "        predicted_graph = Graph()\n",
    "        nodes = list(parts)\n",
    "        \n",
    "        # Add edges to the predicted graph\n",
    "        for i in range(len(nodes)):\n",
    "            # Find the index of the highest value in the row\n",
    "            j = np.argmax(predicted_adj_matrix[i, :])\n",
    "            if i != j and j < len(nodes):  # Ensure we don't add self-loops and j is within bounds\n",
    "                predicted_graph.add_undirected_edge(nodes[i], nodes[j])\n",
    "        \n",
    "        return predicted_graph\n",
    "\n",
    "# Load the final model\n",
    "prediction_model = FFNPredictionModel(model, max_nodes)\n",
    "\n",
    "# For illustration, we compute the eval score on a portion of the training data\n",
    "instances = [(graph.get_parts(), graph) for graph in train_graphs[:1000]]\n",
    "eval_score = evaluate(prediction_model, instances)\n",
    "\n",
    "print(f'Evaluation score: {eval_score:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Binary Adjacency Matrix:\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from typing import Set\n",
    "import numpy as np\n",
    "import torch\n",
    "from part import Part\n",
    "\n",
    "class FFNPredictionModel:\n",
    "    def __init__(self, model, max_nodes, threshold=0.35):\n",
    "        self.model = model\n",
    "        self.max_nodes = max_nodes\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def predict_adjacency_matrix(self, parts: Set[Part]) -> np.ndarray:\n",
    "        # Create one-hot encoded node features\n",
    "        node_features = np.eye(self.max_nodes)[:len(parts)]\n",
    "        \n",
    "        # Pad the node features to ensure they have the same size as max_nodes\n",
    "        padded_features = np.zeros((self.max_nodes, self.max_nodes))\n",
    "        padded_features[:node_features.shape[0], :node_features.shape[1]] = node_features\n",
    "        \n",
    "        # Convert to tensor and add batch dimension\n",
    "        padded_features_tensor = torch.tensor(padded_features, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        # Set the model to evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Predict the adjacency matrix\n",
    "        with torch.no_grad():\n",
    "            predicted_adj_matrix = self.model(padded_features_tensor).squeeze(0).numpy()\n",
    "        \n",
    "        # Apply threshold to get binary adjacency matrix\n",
    "        binary_adj_matrix = (predicted_adj_matrix > self.threshold).astype(int)\n",
    "        \n",
    "        # Return the binary adjacency matrix\n",
    "        return binary_adj_matrix\n",
    "\n",
    "# Example usage\n",
    "# Assuming `model` and `max_nodes` are already defined and the model is trained\n",
    "\n",
    "# Create an instance of the prediction model\n",
    "prediction_model = FFNPredictionModel(model, max_nodes)\n",
    "\n",
    "# Example parts set for debugging\n",
    "example_parts = {Part(part_id=5, family_id=1), Part(part_id=7, family_id=1), Part(part_id=4, family_id=1)}\n",
    "\n",
    "# Get the predicted binary adjacency matrix\n",
    "predicted_binary_matrix = prediction_model.predict_adjacency_matrix(example_parts)\n",
    "\n",
    "# Print the predicted binary adjacency matrix\n",
    "print(\"Predicted Binary Adjacency Matrix:\")\n",
    "print(predicted_binary_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
